{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from __future__ import print_function, division\n",
    "from future.utils import iteritems\n",
    "from builtins import range\n",
    "\n",
    "import nltk\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "sentence = \"these phones had so much static, you could not hear!!!  we ended up having to return the phones and find something that we could actually use!\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "trigrams = {}\n",
    "text_article = sentence.lower()\n",
    "tokens = nltk.tokenize.word_tokenize(text_article)\n",
    "for i in range(len(tokens) - 2):\n",
    "    key_word = (tokens[i], tokens[i+2])\n",
    "    if key_word not in trigrams:\n",
    "        trigrams[key_word] = []\n",
    "    trigrams[key_word].append(tokens[i+1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "trigrams"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{('these', 'had'): ['phones'],\n",
       " ('phones', 'so'): ['had'],\n",
       " ('had', 'much'): ['so'],\n",
       " ('so', 'static'): ['much'],\n",
       " ('much', ','): ['static'],\n",
       " ('static', 'you'): [','],\n",
       " (',', 'could'): ['you'],\n",
       " ('you', 'not'): ['could'],\n",
       " ('could', 'hear'): ['not'],\n",
       " ('not', '!'): ['hear'],\n",
       " ('hear', '!'): ['!'],\n",
       " ('!', '!'): ['!'],\n",
       " ('!', 'we'): ['!'],\n",
       " ('!', 'ended'): ['we'],\n",
       " ('we', 'up'): ['ended'],\n",
       " ('ended', 'having'): ['up'],\n",
       " ('up', 'to'): ['having'],\n",
       " ('having', 'return'): ['to'],\n",
       " ('to', 'the'): ['return'],\n",
       " ('return', 'phones'): ['the'],\n",
       " ('the', 'and'): ['phones'],\n",
       " ('phones', 'find'): ['and'],\n",
       " ('and', 'something'): ['find'],\n",
       " ('find', 'that'): ['something'],\n",
       " ('something', 'we'): ['that'],\n",
       " ('that', 'could'): ['we'],\n",
       " ('we', 'actually'): ['could'],\n",
       " ('could', 'use'): ['actually'],\n",
       " ('actually', '!'): ['use']}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "trigram_probabilities = {}\n",
    "for key_word, words in iteritems(trigrams):\n",
    "    # create a dictionary of word -> count\n",
    "    if len(set(words)) > 1:\n",
    "        # only do this when there are different possibilities for a middle word\n",
    "        d = {}\n",
    "        n = 0\n",
    "        for w in words:\n",
    "            if w not in d:\n",
    "                d[w] = 0\n",
    "            d[w] += 1\n",
    "            n += 1\n",
    "        for w, c in iteritems(d):\n",
    "            d[w] = float(c) / n\n",
    "        trigram_probabilities[key_word] = d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def random_sample(d):\n",
    "    # choose a random sample from dictionary where values are the probabilities\n",
    "    r = random.random()\n",
    "    cumulative = 0\n",
    "    for w, p in iteritems(d):\n",
    "        cumulative += p\n",
    "        if r < cumulative:\n",
    "            return w"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def test_spinner():\n",
    "    review = sentence\n",
    "    text_article = review.lower()\n",
    "    print(\"Original:\\n\", text_article)\n",
    "    tokens = nltk.tokenize.word_tokenize(text_article)\n",
    "    for i in range(len(tokens) - 2):\n",
    "        if random.random() < 0.2: # 20% chance of replacement\n",
    "            key_word = (tokens[i], tokens[i+2])\n",
    "            if key_word in trigram_probabilities:\n",
    "                w = random_sample(trigram_probabilities[key_word])\n",
    "                tokens[i+1] = w\n",
    "    print(\"Spinner:\")\n",
    "    print(\" \".join(tokens).replace(\" .\", \".\").replace(\" '\", \"'\").replace(\" ,\", \",\").replace(\"$ \", \"$\").replace(\" !\", \"!\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "test_spinner()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original:\n",
      " these phones had so much static, you could not hear!!!  we ended up having to return the phones and find something that we could actually use!\n",
      "Spinner:\n",
      "these phones had so much static, you could not hear!!! we ended up having to return the phones and find something that we could actually use!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "olympus_dwv",
   "display_name": "olympus_dwv",
   "language": "python"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}